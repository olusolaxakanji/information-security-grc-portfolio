# Control Testing Workbook

**Emyzer Technology – ServiceNow GRC Control Testing Document**

---

## Testing Metadata

| Field | Value |
|-------|-------|
| **Test Plan Name** | [Control Testing Plan Name] |
| **Test Plan ID** | [CT-YYYY-###] |
| **Testing Type** | Design Effectiveness / Operating Effectiveness / Both |
| **Testing Period** | [Start Date] to [End Date] |
| **Scope** | [Framework, System, or Process being tested] |
| **Owner** | [Test Owner Name] |
| **Owning Group** | [Internal Audit / IT Security / Compliance Team] |
| **State** | Planning / In Progress / Under Review / Complete |
| **Report Date** | [YYYY-MM-DD] |
| **Related Framework** | [SOC 2 / ISO 27001 / NIST 800-53 / etc.] |
| **Knowledge Base** | Governance, Risk, and Compliance |

---

## Executive Summary

**Purpose:** [One sentence describing why this control testing was conducted.]

**Scope Summary:** [Brief description of controls tested, systems covered, and testing period.]

**Key Findings:**
- Total Controls Tested: [#]
- Effective: [#] ([%])
- Partially Effective: [#] ([%])
- Ineffective: [#] ([%])
- Not Tested: [#] ([%])

**Overall Assessment:** Effective / Effective with Exceptions / Ineffective

**Priority Remediation Items:** [1-2 sentences summarizing critical gaps requiring immediate attention.]

---

## A. Testing Objectives

This control testing was conducted to:

1. [Objective 1: e.g., Assess design effectiveness of controls against framework requirements]
2. [Objective 2: e.g., Evaluate operating effectiveness through evidence examination and testing]
3. [Objective 3: e.g., Identify control gaps and deficiencies requiring remediation]
4. [Objective 4: e.g., Support audit readiness for upcoming external assessment]
5. [Objective 5: e.g., Validate remediation of previously identified findings]

---

## B. Scope and Methodology

### Controls in Scope

| Framework Domain | Control Count | Control IDs |
|------------------|---------------|-------------|
| [Domain 1: e.g., Access Control] | [#] | [AC-1, AC-2, AC-3...] |
| [Domain 2: e.g., Change Management] | [#] | [CM-1, CM-2, CM-3...] |
| [Domain 3: e.g., Incident Response] | [#] | [IR-1, IR-2, IR-3...] |
| [Domain 4: e.g., Risk Assessment] | [#] | [RA-1, RA-2, RA-3...] |
| **Total** | **[#]** | |

### Testing Methodology

| Test Type | Description | When Applied |
|-----------|-------------|--------------|
| **Inquiry** | Interviews with control owners and operators | All controls |
| **Observation** | Direct observation of control execution | Automated/manual process controls |
| **Inspection** | Examination of documents and evidence | All controls |
| **Re-performance** | Independent execution of control procedures | Sample-based testing |

### Sampling Methodology

| Population Size | Sample Size | Basis |
|-----------------|-------------|-------|
| 1-10 | All items | 100% coverage |
| 11-50 | 10 items | Statistical sampling |
| 51-250 | 25 items | Statistical sampling |
| 251-500 | 30 items | Statistical sampling |
| 500+ | 40 items | Statistical sampling |

**Sampling Period:** [Testing covered transactions/activities from MM/DD/YYYY to MM/DD/YYYY]

---

## C. Control Testing Results

### C.1 Control Testing Summary

| Control ID | Control Title | Framework Reference | Control Owner | Test Type | Design Effective | Operating Effective | Overall Rating | Findings |
|------------|---------------|---------------------|---------------|-----------|------------------|---------------------|----------------|----------|
| [CTRL-001] | [Control Title] | [e.g., SOC 2 CC6.1] | [Owner Name] | Design + Operating | Yes / No / Partial | Yes / No / Partial / N/A | Effective / Partial / Ineffective | [Finding ID or "None"] |
| [CTRL-002] | [Control Title] | [Framework Ref] | [Owner] | [Type] | [Result] | [Result] | [Rating] | [Finding] |
| [CTRL-003] | [Control Title] | [Framework Ref] | [Owner] | [Type] | [Result] | [Result] | [Rating] | [Finding] |
| [CTRL-004] | [Control Title] | [Framework Ref] | [Owner] | [Type] | [Result] | [Result] | [Rating] | [Finding] |
| [CTRL-005] | [Control Title] | [Framework Ref] | [Owner] | [Type] | [Result] | [Result] | [Rating] | [Finding] |

### C.2 Rating Definitions

| Rating | Definition | Criteria |
|--------|------------|----------|
| **Effective** | Control is properly designed and operating as intended | Design meets requirements; no exceptions in testing |
| **Partially Effective** | Control has minor gaps or inconsistent operation | Design adequate; 1-2 exceptions or minor deviations |
| **Ineffective** | Control is inadequately designed or not operating | Design gaps; 3+ exceptions or significant deviations |
| **Not Tested** | Control excluded from current testing scope | Deferred, N/A to period, or tested separately |

---

## D. Detailed Control Testing Workpapers

### [CTRL-001]: [Control Title]

| Attribute | Details |
|-----------|---------|
| **Control ID** | [CTRL-001] |
| **Control Title** | [Full control title/name] |
| **Control Description** | [Detailed description of what the control does] |
| **Control Type** | Preventive / Detective / Corrective |
| **Control Nature** | Manual / Automated / IT-Dependent Manual |
| **Frequency** | Continuous / Daily / Weekly / Monthly / Quarterly / Annual / Ad-hoc |
| **Framework Mapping** | [SOC 2: CC6.1 / NIST: AC-2 / ISO 27001: A.9.2.1] |
| **Control Owner** | [Name and Title] |
| **Control Operator** | [Name and Title, if different from owner] |
| **Risk Addressed** | [Risk ID from Risk Register, if applicable] |

#### Design Effectiveness Test

| Test Attribute | Details |
|----------------|---------|
| **Test Objective** | [What the test is intended to verify about control design] |
| **Test Procedure** | [Step-by-step procedure performed] |
| **Evidence Examined** | [List of evidence reviewed] |
| **Test Results** | [Detailed findings from design test] |
| **Design Conclusion** | Effective / Partially Effective / Ineffective |

#### Operating Effectiveness Test

| Test Attribute | Details |
|----------------|---------|
| **Test Objective** | [What the test is intended to verify about control operation] |
| **Test Procedure** | [Step-by-step procedure performed] |
| **Population Description** | [Description of full population] |
| **Population Size** | [#] |
| **Sample Size** | [#] |
| **Sample Selection Method** | Random / Haphazard / All items / Risk-based |
| **Testing Period** | [MM/DD/YYYY to MM/DD/YYYY] |
| **Evidence Examined** | [List of evidence reviewed for each sample item] |
| **Exceptions Identified** | [# of exceptions] |
| **Exception Details** | [Description of each exception found] |
| **Operating Conclusion** | Effective / Partially Effective / Ineffective / N/A |

#### Overall Control Assessment

| Attribute | Details |
|-----------|---------|
| **Overall Rating** | Effective / Partially Effective / Ineffective |
| **Findings** | [Finding ID, if applicable] |
| **Recommendations** | [Specific recommendations for improvement] |
| **Management Response** | [Control owner's response to findings] |
| **Tested By** | [Tester Name] |
| **Test Date** | [YYYY-MM-DD] |
| **Reviewed By** | [Reviewer Name] |
| **Review Date** | [YYYY-MM-DD] |

---

### [CTRL-002]: [Control Title]

[Repeat the detailed workpaper structure above for each control tested]

---

## E. Evidence Inventory

| Evidence ID | Evidence Description | Control(s) Supported | Source System | Date Obtained | Retention Location | Confidentiality |
|-------------|---------------------|----------------------|---------------|---------------|-------------------|-----------------|
| [E-001] | [e.g., User access review documentation] | [CTRL-001, CTRL-003] | [ServiceNow / AD / etc.] | [YYYY-MM-DD] | [File path or system] | Public / Internal / Confidential |
| [E-002] | [e.g., Change approval tickets] | [CTRL-002] | [Source] | [Date] | [Location] | [Classification] |
| [E-003] | [e.g., Security awareness training records] | [CTRL-004] | [Source] | [Date] | [Location] | [Classification] |
| [E-004] | [e.g., Incident response logs] | [CTRL-005] | [Source] | [Date] | [Location] | [Classification] |
| [E-005] | [e.g., Vulnerability scan reports] | [CTRL-006] | [Source] | [Date] | [Location] | [Classification] |
| [E-006] | [e.g., Backup restoration test results] | [CTRL-007] | [Source] | [Date] | [Location] | [Classification] |
| [E-007] | [e.g., Policy acknowledgment records] | [CTRL-008] | [Source] | [Date] | [Location] | [Classification] |
| [E-008] | [e.g., System configuration screenshots] | [CTRL-009] | [Source] | [Date] | [Location] | [Classification] |

---

## F. Findings and Remediation Tracker

### F.1 Findings Summary

| Finding ID | Finding Title | Severity | Control(s) Affected | Status |
|------------|---------------|----------|---------------------|--------|
| [F-001] | [Brief title] | Critical / High / Medium / Low | [CTRL-###] | Open / In Progress / Closed |
| [F-002] | [Brief title] | [Severity] | [Control(s)] | [Status] |
| [F-003] | [Brief title] | [Severity] | [Control(s)] | [Status] |

### F.2 Detailed Findings

#### [F-001]: [Finding Title]

| Attribute | Details |
|-----------|---------|
| **Finding ID** | [F-001] |
| **Finding Title** | [Descriptive title of the finding] |
| **Control(s) Affected** | [CTRL-###] |
| **Severity** | Critical / High / Medium / Low |
| **Condition** | [What was found—factual description of the gap or issue] |
| **Criteria** | [What should be in place—framework requirement or policy] |
| **Cause** | [Root cause analysis—why the condition exists] |
| **Effect/Risk** | [Impact—what could happen if not addressed] |
| **Recommendation** | [Specific, actionable remediation steps] |
| **Management Response** | [Control owner's response and agreement/disagreement] |
| **Remediation Plan** | [Detailed steps management will take] |
| **Responsible Party** | [Name and Title] |
| **Target Completion Date** | [YYYY-MM-DD] |
| **Status** | Open / In Progress / Closed |
| **Closure Evidence** | [Evidence required to close finding] |
| **Actual Completion Date** | [YYYY-MM-DD, when closed] |
| **Verified By** | [Name of person who verified closure] |

### F.3 Severity Definitions

| Severity | Definition | Remediation Timeline |
|----------|------------|---------------------|
| **Critical** | Control failure that could result in material misstatement, significant breach, or regulatory violation | Immediate (0-7 days) |
| **High** | Significant control weakness that increases risk exposure substantially | 30 days |
| **Medium** | Moderate control gap that should be addressed to strengthen control environment | 60-90 days |
| **Low** | Minor improvement opportunity; does not significantly impact control effectiveness | 180 days or next cycle |

---

## G. Framework Mapping

| Framework | Description | Controls Tested |
|-----------|-------------|-----------------|
| **SOC 2 Type II** | Service Organization Controls | CC1.x (Control Environment), CC2.x (Communication), CC3.x (Risk Assessment), CC4.x (Monitoring), CC5.x (Control Activities), CC6.x (Logical Access), CC7.x (System Operations), CC8.x (Change Management), CC9.x (Risk Mitigation) |
| **ISO/IEC 27001:2022** | Information Security Management | A.5 (Organizational), A.6 (People), A.7 (Physical), A.8 (Technological) |
| **NIST SP 800-53 Rev. 5** | Security and Privacy Controls | AC, AT, AU, CA, CM, CP, IA, IR, MA, MP, PE, PL, PS, RA, SA, SC, SI |
| **NIST Cybersecurity Framework** | Cybersecurity Risk Management | ID, PR, DE, RS, RC, GV |
| **COBIT 2019** | IT Governance | DSS01-06, BAI06, APO12 |
| **PCI DSS 4.0** | Payment Card Security | Requirements 1-12 |

---

## H. Testing Summary by Domain

### [Domain 1: Access Control]

| Metric | Value |
|--------|-------|
| **Controls Tested** | [#] |
| **Effective** | [#] ([%]) |
| **Partially Effective** | [#] ([%]) |
| **Ineffective** | [#] ([%]) |
| **Findings Identified** | [#] |

**Domain Assessment:** [Summary statement on overall access control effectiveness]

**Key Observations:**
- [Observation 1]
- [Observation 2]
- [Observation 3]

---

### [Domain 2: Change Management]

| Metric | Value |
|--------|-------|
| **Controls Tested** | [#] |
| **Effective** | [#] ([%]) |
| **Partially Effective** | [#] ([%]) |
| **Ineffective** | [#] ([%]) |
| **Findings Identified** | [#] |

**Domain Assessment:** [Summary statement]

**Key Observations:**
- [Observation 1]
- [Observation 2]
- [Observation 3]

---

### [Domain 3: Incident Response]

[Repeat structure for each domain tested]

---

## I. Recommendations Summary

### Immediate Actions (0-30 Days)

| Priority | Recommendation | Related Finding(s) | Responsible Party |
|----------|----------------|-------------------|-------------------|
| 1 | [Recommendation] | [F-###] | [Name/Role] |
| 2 | [Recommendation] | [F-###] | [Name/Role] |
| 3 | [Recommendation] | [F-###] | [Name/Role] |

### Short-Term Actions (30-90 Days)

| Priority | Recommendation | Related Finding(s) | Responsible Party |
|----------|----------------|-------------------|-------------------|
| 1 | [Recommendation] | [F-###] | [Name/Role] |
| 2 | [Recommendation] | [F-###] | [Name/Role] |

### Process Improvement Opportunities

| Opportunity | Benefit | Effort |
|-------------|---------|--------|
| [Improvement 1] | [Expected benefit] | Low / Medium / High |
| [Improvement 2] | [Expected benefit] | [Effort] |

---

## J. Related Documents

1. [Related Policy Name]
2. [Previous Control Testing Report]
3. [Risk Assessment Report]
4. [External Audit Report]
5. [Remediation Tracking Document]
6. [Control Matrix / RACI]

---

## K. Approval and Sign-Off

| Role | Name | Signature | Date |
|------|------|-----------|------|
| Test Lead | [Name] | | [YYYY-MM-DD] |
| Quality Reviewer | [Name] | | [YYYY-MM-DD] |
| Control Owner(s) | [Name] | | [YYYY-MM-DD] |
| IT Security Manager | [Name] | | [YYYY-MM-DD] |
| Internal Audit Manager | [Name] | | [YYYY-MM-DD] |

### Review Comments

| Date | Reviewer | Comments |
|------|----------|----------|
| [YYYY-MM-DD] | [Name] | "[Comments on testing results and findings]" |

---

*This control testing document was generated from ServiceNow GRC and formatted for portfolio presentation.*

---

## Template Usage Notes (Remove Before Use)

### How to Use This Template

1. **Replace all bracketed placeholders** `[text]` with your specific content
2. **Duplicate Section D** for each control tested (detailed workpaper)
3. **Duplicate Finding sections** in Section F for each finding identified
4. **Customize framework mapping** based on your compliance requirements
5. **Remove this section** before publishing

### Control Testing Best Practices

| Practice | Rationale |
|----------|-----------|
| **Test both design and operating effectiveness** | Design confirms control is properly configured; operating confirms it works consistently |
| **Document population and sample clearly** | Supports defensibility of conclusions |
| **Use consistent evidence IDs** | Enables traceability from control to evidence |
| **Separate condition from cause** | Helps identify root cause for effective remediation |
| **Include management response** | Documents accountability and agreement |
| **Track findings to closure** | Demonstrates remediation and continuous improvement |

### Common Evidence Types by Control Domain

| Domain | Common Evidence |
|--------|-----------------|
| **Access Control** | User access lists, access reviews, provisioning tickets, termination checklists, privilege access logs |
| **Change Management** | Change tickets, approval workflows, CAB meeting minutes, deployment logs, rollback procedures |
| **Incident Response** | Incident tickets, postmortem reports, communication logs, escalation records |
| **Security Awareness** | Training completion records, phishing simulation results, policy acknowledgments |
| **Vulnerability Management** | Scan reports, remediation tickets, patch deployment logs, exception requests |
| **Backup & Recovery** | Backup logs, restoration test results, DR test documentation |
| **Logging & Monitoring** | SIEM alerts, log retention configurations, monitoring dashboards |

### ServiceNow GRC Integration Notes

- Control definitions map to `sn_compliance_control` table
- Test plans map to `sn_audit_test_plan` table
- Test results map to `sn_audit_test_result` table
- Findings map to `sn_audit_finding` table
- Evidence maps to `sn_grc_evidence` table

### Test Status Workflow

```
Planning → In Progress → Evidence Collection → Testing → Review → Complete
                ↓
           Finding Identified → Remediation → Validation → Closed
```
